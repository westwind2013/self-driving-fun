{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "\n",
    "In this project, our goal is to write a software pipeline to identify the lane boundaries in a video. Major steps of this project are the following:\n",
    "\n",
    "1. Camera calibration and image undistortion\n",
    "\n",
    "2. Threshold image in various metrics (gradient, gradient angle, color space)\n",
    "\n",
    "3. Perspective transform\n",
    "\n",
    "4. Lane line pixel detection and Line Fitting\n",
    "\n",
    "5. Calculation of curvature radius and car position to lane center\n",
    "\n",
    "6. Output images with lane detection information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane line Finding Pipeline\n",
    "\n",
    "### I. Image Undistortion based on Camera Calibration\n",
    "\n",
    "With the given chessboard images, we perform camera calibration. This step provides us the calibration matrix and distortion coefficients used for undistorting images. Below we demonstrate the correctness of the calibration as well as undistortion using image *calibration2.jpg* (On the left is the original image, and on the right is the undistorted image)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./output_images/calibration2.jpg\"></td>\n",
    "        <td><img src=\"./output_images/calibration2_undistorted.jpg\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Below we can the undistortion of test images. Below is the original images. \n",
    "\n",
    "![Original](./resources/original.png)\n",
    "\n",
    "Following is the undistorted ones. \n",
    "\n",
    "![Original](./resources/undistorted.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Obtain the Thresholded Binary Image\n",
    "\n",
    "To facilitate detection of lane lines, we threshold gradient and different color channels. The main idea is threshold using various metrics. We select pixels satisfying $(g_angle & h_gradient) | (rg & l) | s$, \n",
    "\n",
    "* g_angle: gradient angle between ($\\pi/4, \\pi/2$] \n",
    "* h_gradient: gradient between (10, 200) \n",
    "* rg: R&G channel in RGB space between (180, 255)\n",
    "* s: S channel in HLS space between (90, 255)\n",
    "* l: L channel in HLS space between (155, 220)\n",
    "\n",
    "The selection consists of three parts: (1) $(g_angle & h_gradient)$ for vertical lines detection; (2) (rg & l) for yellow and white color selection; and (3) $s$ for general pixel detection which is resilient to the light condition. \n",
    "\n",
    "\n",
    "\n",
    "![Original](./resources/thresholded.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Perspective Transform\n",
    "\n",
    "To perform a perspective transform, we manually select four vertices along the lane lines to form a polygon. We map these points to destination points depicting two parallel lines after the transformation. In this transformation, we obtain the transform matrix and its inverse, which can be respectively used to warp and unwarp images. \n",
    "\n",
    "![Original](./output_images/perspective_transform.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Lane Line Pixel Detection and Fitting\n",
    "\n",
    "Lane line pixel detection is based on ideas combined from following:\n",
    "    \n",
    "* Histogram peaks: Two lane lines are the two peaks in the bottom half of the histogram of a warped image\n",
    "\n",
    "* Sliding window: X-value of adjacent/near Pixels in the same lane lines varies only slightly\n",
    "\n",
    "On the left below is an exmaple showing histogram peaks. The overall algorithm works as below. We cut the image into 10 sub-images evenly in horizontal direction. Starting from the bottom sub-image we search for pixels of lane lines until we finish, which is known as sliding window. In each sub-image (sliding window), we search for pixels in the range ($x - margin, x+ margin$). Based on the found pixels, we may update the new $x$ values via the mean of pixels and continue the search in the next window. With this algorithm, we perform lane line detection and polynomial fitting as shown below on the right. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./resources/histogram.png\"></td>\n",
    "        <td><img src=\"./resources/fit.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Curvature Radius and Car Position to Lane Center \n",
    "\n",
    "We perform the calculation of radius of curvature as discussed in the course. \n",
    "\n",
    "Car Position to Lane Center: The mean of the lane pixels at the image bottom minus the center of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Output Lane Info\n",
    "\n",
    "* Warp the detected lane boundaries back onto the original image\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Discrete Images\n",
    "\n",
    "Applying Pipeline to Discrete Images\n",
    "\n",
    "The pipeline works well for all test images. \n",
    "\n",
    "![marked_images](./output_images/images_marked.jpg)\n",
    "\n",
    "\n",
    "## Videos\n",
    "\n",
    "Besides the aforementioned, video pipeline did following more. \n",
    "\n",
    "* It performs the suggested optimization for searching lane line pixels, i.e., it searches pixels in the current image frame along the fitted lines from the previous ones. \n",
    "\n",
    "* It detect bad detection cases, like the detected lane lines are too close or too far, lane line is missing, or the curvature radius of the detected two lines differ too much. \n",
    "    \n",
    "    * If this happens, in order to plot lane lines we use the average of old fitted lane lines\n",
    "    \n",
    "    * Once this happens, our search in the next frame adopts the original sliding-window algorithm for pixel finding; otherwise, the optimized way is adopted. \n",
    "\n",
    "* It average the last 10 fitted lane lines for smoothing the plotting in videos. \n",
    "\n",
    "The pipeline works well with [project_video.mp4](./output_videos/project_video.mp4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "### Shortcomings\n",
    "\n",
    "* Parameter setting, especially for thresholding image, is the most challenging part. Parameters scatters around the project, and it is hard to find the best parameter combination in a huge search space. \n",
    "\n",
    "* The pipeline does not deal with the challege videos well due to the strong/weak light, blurred lines, and sharp turns. \n",
    "\n",
    "### Improvement\n",
    "\n",
    "* A more systematic and atuomatic way is needed for better parameter setting\n",
    "\n",
    "* Varying strategies are needed for various road situation, like strong lights, blurred lines, and sharp turns. Like high-order polynomial fitting might help for sharp turns. Better pixel selection in S channel of HSL color space might be needed for strong/weak light condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
